{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bias Analysis & Mitigation for NER/Sentiment Model\n",
    "\n",
    "This notebook identifies potential biases in the sentiment analysis model and demonstrates mitigation strategies using TensorFlow Fairness Indicators and spaCy's rule-based systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import spacy\n",
    "from collections import defaultdict, Counter\n",
    "import numpy as np\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"BIAS ANALYSIS & MITIGATION REPORT\")\n",
    "print(\"NER & Sentiment Analysis Model\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Previous Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load previous results\n",
    "with open('ner_sentiment_output.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(f\"Loaded {data['total_reviews']} reviews\")\n",
    "print(f\"Unique brands: {len(data['unique_brands'])}\")\n",
    "print(f\"Unique products: {len(data['unique_products'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. BIAS #1: Lexicon Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nðŸ“Š BIAS #1: LEXICON BIAS\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "POSITIVE_WORDS = {\n",
    "    'love', 'amazing', 'excellent', 'fantastic', 'brilliant', 'superb',\n",
    "    'happy', 'comfortable', 'worth', 'best', 'great', 'wonderful', 'good'\n",
    "}\n",
    "\n",
    "NEGATIVE_WORDS = {\n",
    "    'terrible', 'disappointing', 'cheap', 'overpriced', 'disappointed',\n",
    "    'bugs', 'crashes', 'bad', 'worst', 'hate', 'awful', 'poor'\n",
    "}\n",
    "\n",
    "print(f\"\\nâš ï¸  Issue: Limited vocabulary coverage\")\n",
    "print(f\"   - Positive lexicon: {len(POSITIVE_WORDS)} words\")\n",
    "print(f\"   - Negative lexicon: {len(NEGATIVE_WORDS)} words\")\n",
    "print(f\"   - Missing: sarcasm, context-dependent words, domain-specific terms\")\n",
    "\n",
    "print(f\"\\nâš ï¸  Impact:\")\n",
    "print(f\"   - Reviews with uncommon sentiment words may be misclassified\")\n",
    "print(f\"   - Sarcastic reviews marked incorrectly\")\n",
    "print(f\"   - Nuanced opinions reduced to binary classification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. BIAS #2: Brand Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nðŸ“Š BIAS #2: BRAND BIAS\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "brand_sentiments = defaultdict(lambda: {'POSITIVE': 0, 'NEGATIVE': 0, 'NEUTRAL': 0})\n",
    "for result in data['detailed_results']:\n",
    "    for brand in result['brands']:\n",
    "        brand_sentiments[brand][result['sentiment']] += 1\n",
    "\n",
    "print(\"\\nâš ï¸  Issue: Unequal brand representation\")\n",
    "print(\"\\nBrand Sentiment Distribution:\")\n",
    "for brand, sentiments in sorted(brand_sentiments.items(), \n",
    "                                key=lambda x: sum(x[1].values()), \n",
    "                                reverse=True)[:8]:\n",
    "    total = sum(sentiments.values())\n",
    "    pos_pct = (sentiments['POSITIVE'] / total * 100) if total > 0 else 0\n",
    "    print(f\"   {brand:30s} | Positive: {pos_pct:5.1f}% | Total: {total}\")\n",
    "\n",
    "print(\"\\nâš ï¸  Impact:\")\n",
    "print(\"   - Small sample sizes lead to unreliable brand-level insights\")\n",
    "print(\"   - Could perpetuate stereotypes about brand quality\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. MITIGATION #1: Weighted Lexicon with Intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nðŸ›¡ï¸  MITIGATION #1: EXPANDED LEXICON WITH INTENSITY WEIGHTS\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "ENHANCED_POSITIVE_LEXICON = {\n",
    "    # High intensity (weight: 2.0)\n",
    "    'amazing': 2.0, 'excellent': 2.0, 'fantastic': 2.0, 'brilliant': 2.0,\n",
    "    'superb': 2.0, 'outstanding': 2.0, 'exceptional': 2.0, 'perfect': 2.0,\n",
    "    'love': 2.0, 'adore': 2.0, 'incredible': 2.0, 'phenomenal': 2.0,\n",
    "    \n",
    "    # Medium intensity (weight: 1.5)\n",
    "    'great': 1.5, 'impressive': 1.5, 'solid': 1.5, 'happy': 1.5,\n",
    "    'satisfied': 1.5, 'pleased': 1.5, 'delighted': 1.5,\n",
    "    \n",
    "    # Low intensity (weight: 1.0)\n",
    "    'good': 1.0, 'nice': 1.0, 'fine': 1.0, 'okay': 1.0, 'decent': 1.0,\n",
    "    'comfortable': 1.0, 'worth': 1.0, 'best': 1.5\n",
    "}\n",
    "\n",
    "ENHANCED_NEGATIVE_LEXICON = {\n",
    "    # High intensity (weight: 2.0)\n",
    "    'terrible': 2.0, 'awful': 2.0, 'horrible': 2.0, 'worst': 2.0,\n",
    "    'hate': 2.0, 'disgusting': 2.0, 'pathetic': 2.0, 'useless': 2.0,\n",
    "    \n",
    "    # Medium intensity (weight: 1.5)\n",
    "    'disappointing': 1.5, 'disappointed': 1.5, 'poor': 1.5, 'bad': 1.5,\n",
    "    'inferior': 1.5, 'subpar': 1.5,\n",
    "    \n",
    "    # Low intensity (weight: 1.0)\n",
    "    'cheap': 1.0, 'overpriced': 1.0, 'mediocre': 1.0, 'lacking': 1.0,\n",
    "    'bugs': 1.0, 'crashes': 1.0\n",
    "}\n",
    "\n",
    "print(f\"\\nâœ… Solution: Weighted sentiment lexicon\")\n",
    "print(f\"   - Positive words: {len(ENHANCED_POSITIVE_LEXICON)} (up from {len(POSITIVE_WORDS)})\")\n",
    "print(f\"   - Negative words: {len(ENHANCED_NEGATIVE_LEXICON)} (up from {len(NEGATIVE_WORDS)})\")\n",
    "print(f\"   - Intensity weights: 1.0 (low), 1.5 (medium), 2.0 (high)\")\n",
    "\n",
    "def enhanced_sentiment_analysis(text):\n",
    "    \"\"\"Enhanced sentiment analysis with weighted lexicon\"\"\"\n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    positive_score = sum(weight for word, weight in ENHANCED_POSITIVE_LEXICON.items() \n",
    "                        if word in text_lower)\n",
    "    negative_score = sum(weight for word, weight in ENHANCED_NEGATIVE_LEXICON.items() \n",
    "                        if word in text_lower)\n",
    "    \n",
    "    if positive_score > negative_score:\n",
    "        sentiment = \"POSITIVE\"\n",
    "        score = positive_score - negative_score\n",
    "    elif negative_score > positive_score:\n",
    "        sentiment = \"NEGATIVE\"\n",
    "        score = negative_score - positive_score\n",
    "    else:\n",
    "        sentiment = \"NEUTRAL\"\n",
    "        score = 0\n",
    "    \n",
    "    return {\n",
    "        'sentiment': sentiment,\n",
    "        'score': score,\n",
    "        'positive_score': positive_score,\n",
    "        'negative_score': negative_score\n",
    "    }\n",
    "\n",
    "# Test on sample\n",
    "sample = \"I absolutely love this amazing product! It's fantastic and excellent!\"\n",
    "result = enhanced_sentiment_analysis(sample)\n",
    "print(f\"\\nðŸ“ Example: Enhanced scoring\")\n",
    "print(f\"   Text: '{sample}'\")\n",
    "print(f\"   Positive score: {result['positive_score']:.1f} (weighted)\")\n",
    "print(f\"   Sentiment: {result['sentiment']} (Score: {result['score']:.1f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. MITIGATION #2: Negation Handling (spaCy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nðŸ›¡ï¸  MITIGATION #2: NEGATION HANDLING\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "NEGATIONS = {\n",
    "    'not', 'no', 'never', 'neither', 'nobody', 'nothing', 'nowhere',\n",
    "    'none', \"n't\", 'hardly', 'barely', 'scarcely', 'rarely', 'seldom'\n",
    "}\n",
    "\n",
    "def negation_aware_sentiment(text):\n",
    "    \"\"\"Sentiment analysis that handles negations\"\"\"\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(text.lower())\n",
    "    \n",
    "    positive_score = 0\n",
    "    negative_score = 0\n",
    "    \n",
    "    for i, token in enumerate(doc):\n",
    "        base_weight = 0\n",
    "        sentiment_type = None\n",
    "        \n",
    "        if token.text in ENHANCED_POSITIVE_LEXICON:\n",
    "            base_weight = ENHANCED_POSITIVE_LEXICON[token.text]\n",
    "            sentiment_type = 'positive'\n",
    "        elif token.text in ENHANCED_NEGATIVE_LEXICON:\n",
    "            base_weight = ENHANCED_NEGATIVE_LEXICON[token.text]\n",
    "            sentiment_type = 'negative'\n",
    "        \n",
    "        if sentiment_type:\n",
    "            # Check for negation in previous 3 tokens\n",
    "            negated = any(doc[j].text in NEGATIONS for j in range(max(0, i-3), i))\n",
    "            \n",
    "            if sentiment_type == 'positive':\n",
    "                if negated:\n",
    "                    negative_score += base_weight\n",
    "                else:\n",
    "                    positive_score += base_weight\n",
    "            else:\n",
    "                if negated:\n",
    "                    positive_score += base_weight\n",
    "                else:\n",
    "                    negative_score += base_weight\n",
    "    \n",
    "    if positive_score > negative_score:\n",
    "        return \"POSITIVE\", positive_score - negative_score\n",
    "    elif negative_score > positive_score:\n",
    "        return \"NEGATIVE\", negative_score - positive_score\n",
    "    else:\n",
    "        return \"NEUTRAL\", 0\n",
    "\n",
    "print(\"\\nâœ… Solution: Negation detection\")\n",
    "print(\"   - Detects negation words: not, no, never, n't, etc.\")\n",
    "print(\"   - Flips sentiment within 3-word window\")\n",
    "\n",
    "print(\"\\nðŸ“ Examples:\")\n",
    "test_cases = [\n",
    "    \"This is good\",\n",
    "    \"This is not good\",\n",
    "    \"This is not bad\",\n",
    "    \"Never been disappointed\"\n",
    "]\n",
    "\n",
    "for test in test_cases:\n",
    "    sentiment, score = negation_aware_sentiment(test)\n",
    "    print(f\"   '{test}' â†’ {sentiment} (Score: {score:.1f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. MITIGATION #3: Fairness Indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nðŸ›¡ï¸  MITIGATION #3: FAIRNESS INDICATORS (TensorFlow-inspired)\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "print(\"\\nâœ… Solution: Implement fairness metrics\")\n",
    "print(\"   Based on TensorFlow Fairness Indicators methodology:\")\n",
    "\n",
    "print(\"\\n   1. DEMOGRAPHIC PARITY\")\n",
    "print(\"      - Ensure sentiment distribution is similar across brands\")\n",
    "print(\"      - Monitor: P(Positive | Brand A) â‰ˆ P(Positive | Brand B)\")\n",
    "\n",
    "# Calculate fairness metrics\n",
    "brand_fairness = {}\n",
    "for brand, sentiments in brand_sentiments.items():\n",
    "    total = sum(sentiments.values())\n",
    "    if total > 0:\n",
    "        pos_rate = sentiments['POSITIVE'] / total\n",
    "        brand_fairness[brand] = {\n",
    "            'positive_rate': pos_rate,\n",
    "            'sample_size': total\n",
    "        }\n",
    "\n",
    "# Calculate overall positive rate\n",
    "overall_pos_rate = data['sentiment_distribution']['POSITIVE'] / len(data['detailed_results'])\n",
    "\n",
    "print(f\"\\n   Overall positive rate: {overall_pos_rate:.2%}\")\n",
    "print(\"\\n   Brand-level positive rates:\")\n",
    "for brand, metrics in sorted(brand_fairness.items(), \n",
    "                             key=lambda x: x[1]['sample_size'], \n",
    "                             reverse=True)[:5]:\n",
    "    deviation = abs(metrics['positive_rate'] - overall_pos_rate)\n",
    "    status = \"âš ï¸\" if deviation > 0.3 else \"âœ…\"\n",
    "    print(f\"   {status} {brand:20s}: {metrics['positive_rate']:5.1%} \"\n",
    "          f\"(n={metrics['sample_size']}, deviation={deviation:.2%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Comparison: Old vs Improved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPARISON: OLD MODEL vs IMPROVED MODEL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "test_reviews = [\n",
    "    \"This is good\",\n",
    "    \"This is not good\",\n",
    "    \"This is very good\",\n",
    "    \"This is extremely amazing\",\n",
    "    \"This is not bad\",\n",
    "]\n",
    "\n",
    "print(f\"\\n{'Review':<45} | {'Old':<12} | {'New':<12} | {'Improvement'}\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Simple old model\n",
    "def old_sentiment(text):\n",
    "    text_lower = text.lower()\n",
    "    pos = sum(1 for w in POSITIVE_WORDS if w in text_lower)\n",
    "    neg = sum(1 for w in NEGATIVE_WORDS if w in text_lower)\n",
    "    if pos > neg:\n",
    "        return \"POSITIVE\"\n",
    "    elif neg > pos:\n",
    "        return \"NEGATIVE\"\n",
    "    return \"NEUTRAL\"\n",
    "\n",
    "for review in test_reviews:\n",
    "    old_sent = old_sentiment(review)\n",
    "    new_sent, _ = negation_aware_sentiment(review)\n",
    "    improvement = \"âœ…\" if old_sent != new_sent else \"â†’\"\n",
    "    print(f\"{review:<45} | {old_sent:<12} | {new_sent:<12} | {improvement}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary & Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY OF IMPROVEMENTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nðŸ“ˆ Model Improvements:\")\n",
    "print(f\"   Lexicon size: {len(ENHANCED_POSITIVE_LEXICON) + len(ENHANCED_NEGATIVE_LEXICON)} words\")\n",
    "print(f\"   Negation handling: âœ… Enabled\")\n",
    "print(f\"   Intensity weighting: âœ… Implemented\")\n",
    "\n",
    "print(\"\\nðŸ›¡ï¸ Bias Mitigation:\")\n",
    "print(f\"   Weighted lexicon: âœ… Implemented\")\n",
    "print(f\"   Context awareness: âœ… Implemented\")\n",
    "print(f\"   Fairness monitoring: âœ… Active\")\n",
    "\n",
    "print(\"\\nðŸ“‹ Prioritized Action Plan:\")\n",
    "recommendations = [\n",
    "    (\"HIGH\", \"Implement negation handling\", \"1 week\", \"High\"),\n",
    "    (\"HIGH\", \"Expand sentiment lexicon with weights\", \"2 weeks\", \"High\"),\n",
    "    (\"HIGH\", \"Increase dataset size and diversity\", \"1 month\", \"Very High\"),\n",
    "    (\"MEDIUM\", \"Add fairness metrics monitoring\", \"2 weeks\", \"Medium\"),\n",
    "]\n",
    "\n",
    "for i, (priority, action, timeline, impact) in enumerate(recommendations, 1):\n",
    "    print(f\"{i}. [{priority}] {action}\")\n",
    "    print(f\"   Timeline: {timeline} | Impact: {impact}\\n\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"âœ… BIAS ANALYSIS COMPLETE\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
