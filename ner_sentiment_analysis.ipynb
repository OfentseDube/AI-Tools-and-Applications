{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entity Recognition (NER) & Sentiment Analysis\n",
    "\n",
    "**Goal**: Perform named entity recognition (NER) to extract product names and brands. Analyze sentiment (positive/negative) using a rule-based approach.\n",
    "\n",
    "**Deliverable**: Code snippet and output showing extracted entities and sentiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import json\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"NAMED ENTITY RECOGNITION (NER) & SENTIMENT ANALYSIS\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load spaCy Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load spaCy model for NER\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    print(\"\\n‚úì Loaded spaCy model successfully\\n\")\n",
    "except OSError:\n",
    "    print(\"\\n‚ö† Installing spaCy model...\")\n",
    "    import subprocess\n",
    "    subprocess.run([\"python\", \"-m\", \"spacy\", \"download\", \"en_core_web_sm\"])\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    print(\"‚úì Model installed and loaded\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define Sample Data & Lexicons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample product review data\n",
    "sample_reviews = [\n",
    "    \"I absolutely love my new iPhone 14 Pro from Apple! The camera quality is amazing.\",\n",
    "    \"The Samsung Galaxy S23 is a terrible phone. Battery life is disappointing.\",\n",
    "    \"Just bought Nike Air Max sneakers and they are incredibly comfortable!\",\n",
    "    \"My Sony WH-1000XM5 headphones have excellent noise cancellation. Very happy with this purchase.\",\n",
    "    \"The Dell XPS 15 laptop is overpriced and the keyboard feels cheap.\",\n",
    "    \"Adidas Ultraboost running shoes are fantastic! Best running shoes I've ever owned.\",\n",
    "    \"Disappointed with the Microsoft Surface Pro 9. Too many bugs and crashes.\",\n",
    "    \"The Canon EOS R6 camera from Canon is absolutely brilliant for photography!\",\n",
    "    \"Bought a MacBook Pro from Apple and it's worth every penny. Superb performance!\",\n",
    "    \"The Google Pixel 7 is okay, nothing special but gets the job done.\"\n",
    "]\n",
    "\n",
    "# Define known brands and product patterns\n",
    "KNOWN_BRANDS = {\n",
    "    'Apple', 'Samsung', 'Nike', 'Adidas', 'Sony', 'Dell', 'Microsoft', \n",
    "    'Canon', 'Google', 'iPhone', 'MacBook', 'Surface', 'Pixel', 'Galaxy'\n",
    "}\n",
    "\n",
    "# Rule-based sentiment analysis\n",
    "POSITIVE_WORDS = {\n",
    "    'love', 'amazing', 'excellent', 'fantastic', 'brilliant', 'superb',\n",
    "    'happy', 'comfortable', 'worth', 'best', 'great', 'wonderful', 'good'\n",
    "}\n",
    "\n",
    "NEGATIVE_WORDS = {\n",
    "    'terrible', 'disappointing', 'cheap', 'overpriced', 'disappointed',\n",
    "    'bugs', 'crashes', 'bad', 'worst', 'hate', 'awful', 'poor'\n",
    "}\n",
    "\n",
    "print(f\"Sample reviews: {len(sample_reviews)}\")\n",
    "print(f\"Known brands: {len(KNOWN_BRANDS)}\")\n",
    "print(f\"Positive words: {len(POSITIVE_WORDS)}\")\n",
    "print(f\"Negative words: {len(NEGATIVE_WORDS)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define Entity Extraction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entities(text, doc):\n",
    "    \"\"\"Extract product names and brands using NER and pattern matching\"\"\"\n",
    "    entities = {\n",
    "        'brands': set(),\n",
    "        'products': set(),\n",
    "        'organizations': set()\n",
    "    }\n",
    "    \n",
    "    # Extract entities using spaCy NER\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in ['ORG', 'PRODUCT', 'GPE']:\n",
    "            if any(brand.lower() in ent.text.lower() for brand in KNOWN_BRANDS):\n",
    "                entities['brands'].add(ent.text)\n",
    "            elif ent.label_ == 'PRODUCT':\n",
    "                entities['products'].add(ent.text)\n",
    "            elif ent.label_ == 'ORG':\n",
    "                entities['organizations'].add(ent.text)\n",
    "    \n",
    "    # Additional pattern matching for product names\n",
    "    product_pattern = r'\\b([A-Z][a-z]+(?:\\s+[A-Z][a-z]+)*)\\s+([A-Z0-9]+(?:\\s+[A-Z][a-z]+)*)\\b'\n",
    "    matches = re.findall(product_pattern, text)\n",
    "    for match in matches:\n",
    "        full_product = ' '.join(match)\n",
    "        if any(brand in full_product for brand in KNOWN_BRANDS):\n",
    "            entities['products'].add(full_product)\n",
    "    \n",
    "    # Extract known brands directly\n",
    "    for brand in KNOWN_BRANDS:\n",
    "        if brand.lower() in text.lower():\n",
    "            entities['brands'].add(brand)\n",
    "    \n",
    "    return entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Define Sentiment Analysis Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment(text):\n",
    "    \"\"\"Rule-based sentiment analysis\"\"\"\n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    # Count positive and negative words\n",
    "    positive_count = sum(1 for word in POSITIVE_WORDS if word in text_lower)\n",
    "    negative_count = sum(1 for word in NEGATIVE_WORDS if word in text_lower)\n",
    "    \n",
    "    # Determine sentiment\n",
    "    if positive_count > negative_count:\n",
    "        sentiment = \"POSITIVE\"\n",
    "        score = positive_count - negative_count\n",
    "    elif negative_count > positive_count:\n",
    "        sentiment = \"NEGATIVE\"\n",
    "        score = negative_count - positive_count\n",
    "    else:\n",
    "        sentiment = \"NEUTRAL\"\n",
    "        score = 0\n",
    "    \n",
    "    return {\n",
    "        'sentiment': sentiment,\n",
    "        'score': score,\n",
    "        'positive_words': positive_count,\n",
    "        'negative_words': negative_count\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Process All Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all reviews\n",
    "results = []\n",
    "all_brands = set()\n",
    "all_products = set()\n",
    "\n",
    "print(\"PROCESSING REVIEWS:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for i, review in enumerate(sample_reviews, 1):\n",
    "    doc = nlp(review)\n",
    "    \n",
    "    # Extract entities\n",
    "    entities = extract_entities(review, doc)\n",
    "    \n",
    "    # Analyze sentiment\n",
    "    sentiment_result = analyze_sentiment(review)\n",
    "    \n",
    "    # Store results\n",
    "    result = {\n",
    "        'review_id': i,\n",
    "        'text': review,\n",
    "        'entities': entities,\n",
    "        'sentiment': sentiment_result\n",
    "    }\n",
    "    results.append(result)\n",
    "    \n",
    "    # Aggregate brands and products\n",
    "    all_brands.update(entities['brands'])\n",
    "    all_products.update(entities['products'])\n",
    "    \n",
    "    # Display individual result\n",
    "    print(f\"\\nüìù Review #{i}:\")\n",
    "    print(f\"   Text: {review}\")\n",
    "    print(f\"   Brands: {', '.join(entities['brands']) if entities['brands'] else 'None'}\")\n",
    "    print(f\"   Products: {', '.join(entities['products']) if entities['products'] else 'None'}\")\n",
    "    print(f\"   Sentiment: {sentiment_result['sentiment']} (Score: {sentiment_result['score']})\")\n",
    "    print(f\"   Analysis: {sentiment_result['positive_words']} positive, {sentiment_result['negative_words']} negative words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nüìä Total Reviews Analyzed: {len(sample_reviews)}\")\n",
    "print(f\"\\nüè∑Ô∏è  Unique Brands Extracted: {len(all_brands)}\")\n",
    "print(f\"   {', '.join(sorted(all_brands))}\")\n",
    "\n",
    "print(f\"\\nüì¶ Unique Products Extracted: {len(all_products)}\")\n",
    "if all_products:\n",
    "    for product in sorted(all_products):\n",
    "        print(f\"   - {product}\")\n",
    "\n",
    "# Sentiment distribution\n",
    "sentiment_counts = defaultdict(int)\n",
    "for result in results:\n",
    "    sentiment_counts[result['sentiment']['sentiment']] += 1\n",
    "\n",
    "print(f\"\\nüí≠ Sentiment Distribution:\")\n",
    "for sentiment, count in sorted(sentiment_counts.items()):\n",
    "    percentage = (count / len(sample_reviews)) * 100\n",
    "    print(f\"   {sentiment}: {count} ({percentage:.1f}%)\")\n",
    "\n",
    "# Most mentioned brands\n",
    "brand_mentions = defaultdict(int)\n",
    "for result in results:\n",
    "    for brand in result['entities']['brands']:\n",
    "        brand_mentions[brand] += 1\n",
    "\n",
    "print(f\"\\nüîù Top Mentioned Brands:\")\n",
    "for brand, count in sorted(brand_mentions.items(), key=lambda x: x[1], reverse=True)[:5]:\n",
    "    print(f\"   {brand}: {count} mentions\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ ANALYSIS COMPLETE\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Results to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to file\n",
    "output_data = {\n",
    "    'total_reviews': len(sample_reviews),\n",
    "    'unique_brands': list(all_brands),\n",
    "    'unique_products': list(all_products),\n",
    "    'sentiment_distribution': dict(sentiment_counts),\n",
    "    'detailed_results': [\n",
    "        {\n",
    "            'review_id': r['review_id'],\n",
    "            'text': r['text'],\n",
    "            'brands': list(r['entities']['brands']),\n",
    "            'products': list(r['entities']['products']),\n",
    "            'sentiment': r['sentiment']['sentiment'],\n",
    "            'sentiment_score': r['sentiment']['score']\n",
    "        }\n",
    "        for r in results\n",
    "    ]\n",
    "}\n",
    "\n",
    "with open('ner_sentiment_output.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(output_data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"\\nüíæ Results saved to 'ner_sentiment_output.json'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Visualize Results (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sentiment distribution pie chart\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Pie chart\n",
    "colors = ['#4CAF50', '#F44336', '#9E9E9E']\n",
    "ax1.pie(sentiment_counts.values(), labels=sentiment_counts.keys(), autopct='%1.1f%%',\n",
    "        colors=colors, startangle=90)\n",
    "ax1.set_title('Sentiment Distribution', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Bar chart for top brands\n",
    "top_brands = dict(sorted(brand_mentions.items(), key=lambda x: x[1], reverse=True)[:5])\n",
    "ax2.barh(list(top_brands.keys()), list(top_brands.values()), color='#2196F3')\n",
    "ax2.set_xlabel('Mentions', fontweight='bold')\n",
    "ax2.set_title('Top 5 Brand Mentions', fontsize=14, fontweight='bold')\n",
    "ax2.invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä Visualization complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
